# TranscriÃ§Ã£o de Ãudio com VLibras

AplicaÃ§Ã£o web para transcriÃ§Ã£o de Ã¡udio usando Whisper AI e traduÃ§Ã£o para Libras atravÃ©s do VLibras.

## ğŸš€ Funcionalidades

- **GravaÃ§Ã£o de Ã¡udio** diretamente pelo navegador
- **TranscriÃ§Ã£o automÃ¡tica** usando OpenAI Whisper
- **TraduÃ§Ã£o para Libras** integrada com VLibras
- Interface responsiva e moderna
- Suporte a GPU para processamento mais rÃ¡pido

## ğŸ“‹ PrÃ©-requisitos

- Python 3.8+
- FFmpeg (necessÃ¡rio para o Whisper)
- Navegador moderno com suporte a MediaRecorder API

### InstalaÃ§Ã£o do FFmpeg

**Ubuntu/Debian:**
```bash
sudo apt update
sudo apt install ffmpeg
```

**macOS:**
```bash
brew install ffmpeg
```

**Windows:**
Baixe de [ffmpeg.org](https://ffmpeg.org/download.html)

## ğŸ”§ InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/seu-usuario/projeto-libras.git
cd projeto-libras
```

2. Crie um ambiente virtual (recomendado):
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows
```

3. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

## ğŸ’» Uso

1. Inicie o servidor Flask:
```bash
python app.py
```

2. Acesse no navegador:
```
http://localhost:5000
```

3. Clique em **"Gravar"** para iniciar a gravaÃ§Ã£o de Ã¡udio
4. Clique em **"Parar"** quando terminar
5. O texto transcrito aparecerÃ¡ automaticamente
6. Se habilitado, o VLibras traduzirÃ¡ automaticamente para Libras

## ğŸ› ï¸ Tecnologias Utilizadas

- **Flask** - Framework web Python
- **OpenAI Whisper** - Modelo de transcriÃ§Ã£o de Ã¡udio
- **VLibras** - Tradutor para LÃ­ngua Brasileira de Sinais
- **PyTorch** - Backend para o Whisper
- **Flask-CORS** - Suporte a requisiÃ§Ãµes cross-origin

## ğŸ“ Estrutura do Projeto

```
projeto-libras/
â”œâ”€â”€ app.py              # AplicaÃ§Ã£o Flask principal
â”œâ”€â”€ stt.py              # MÃ³dulo de transcriÃ§Ã£o com Whisper
â”œâ”€â”€ requirements.txt    # DependÃªncias Python
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html     # Interface web
â””â”€â”€ uploads/           # DiretÃ³rio temporÃ¡rio para Ã¡udios
```

## âš™ï¸ ConfiguraÃ§Ã£o

### Modelo Whisper

Por padrÃ£o, o projeto usa o modelo `tiny` para transcriÃ§Ã£o rÃ¡pida. VocÃª pode alterar em `stt.py`:

```python
modelo = whisper.load_model("tiny", device=device)  # tiny, base, small, medium, large
```

**Modelos disponÃ­veis:**
- `tiny` - Mais rÃ¡pido, menos preciso (~75MB)
- `base` - Balance entre velocidade e precisÃ£o (~150MB)
- `small` - Boa precisÃ£o (~500MB)
- `medium` - Alta precisÃ£o (~1.5GB)
- `large` - Maior precisÃ£o (~3GB)

### GPU

O projeto detecta automaticamente se hÃ¡ GPU disponÃ­vel (CUDA). Para forÃ§ar CPU:

```python
device = "cpu"
```

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para:

1. Fazer fork do projeto
2. Criar uma branch para sua feature (`git checkout -b feature/MinhaFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona MinhaFeature'`)
4. Push para a branch (`git push origin feature/MinhaFeature`)
5. Abrir um Pull Request

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo LICENSE para mais detalhes.

## ğŸ™ Agradecimentos

- [OpenAI Whisper](https://github.com/openai/whisper) - Modelo de transcriÃ§Ã£o
- [VLibras](https://www.gov.br/governodigital/pt-br/vlibras) - Tradutor para Libras
- Comunidade open source

## ğŸ“§ Contato

Para dÃºvidas ou sugestÃµes, abra uma issue no GitHub.

---

Desenvolvido com â¤ï¸ para acessibilidade